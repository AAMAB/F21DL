{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d860c16",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# F20DL Group 17 ML Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d3190",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week 1\n",
    "Overview: We shortlisted datasets to work on for the rest of the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf23ba0",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Short-listed Tabular Datasets:\n",
    "1. **Pokémon for Data Mining and Machine Learning** - [Kaggle](https://www.kaggle.com/datasets/alopez247/pokemon)\n",
    "    - <font color='#90ee90'> 721 entries and 23 attributes for each entry, a mix of nominal and numerical data. </font>\n",
    "    - <font color='#90ee90'> There are only 2 attributes with over 50% null values, can be easily cleaned\n",
    "    and still lots of other attributes </font>\n",
    "    - <font color='#90ee90'> The dataset is 732Kb, so it does not use a lot of space. </font>\n",
    "   <br></br>\n",
    "2. **Netflix Movies and TV Shows** - [Kaggle](https://www.kaggle.com/datasets/shivamb/netflix-shows)\n",
    "    - <font color='#90ee90'> Pros:  8807 records with 12 attributes covering all data types (nominal/interval/ratio/ordinal data)</font>\n",
    "    - <font color='#90ee90'> The dataset is 3.4MB.</font>\n",
    "    - <font color='#FF7F7F'> 30% of records have null values for a certain attribute - field can be removed or records can be removed (leaving 6000 records) </font>\n",
    "    <br></br>\n",
    "3. **Video Game Sales** - [Kaggle](https://www.kaggle.com/datasets/gregorut/videogamesales)\n",
    "    - <font color='#90ee90'>The dataset is comprehensive which consist of 16500+ records</font>\n",
    "    - <font color='#90ee90'>This is a well known dataset with lots of papers and code</font>\n",
    "    - <font color='#FF7F7F'>Has a limited number of attributes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198469d9",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Short-listed Computer Vision Datasets\n",
    "\n",
    "4. **Fruits 360** - [Kaggle](https://www.kaggle.com/datasets/moltean/fruits)\n",
    "    - <font color='#90ee90'>The dataset is comprehensive which consist of 90000+ high-quality images of over 100 different classes</font>\n",
    "    - <font color='#90ee90'>The dataset consist of good quality, bad quality, and mixed quality fruit images</font>\n",
    "    - <font color='#90ee90'>This is a well known dataset with lots of papers and code</font>\n",
    "    - <font color='#90ee90'>The dataset has lots of training data which might result in better accuracy</font>\n",
    "    - <font color='#FF7F7F'>The data might require GPUs for training due to the sheer size of the dataset</font>\n",
    "    <br></br>\n",
    "5. **Pokemon Image Dataset** - [Kaggle](https://www.kaggle.com/datasets/vishalsubbiah/pokemon-images-and-types)\n",
    "    - <font color='#90ee90'>Has images of *all* of the Pokemon from generation 1 to 7</font>\n",
    "    - <font color='#90ee90'>810 files/images to identify next evolution from the pre-evoled forms of the current Pokemon</font>\n",
    "    - <font color='#90ee90'>Each Pokemon has two types, primary and secondary. The dataset helps predict the current type of the Pokemon image</font>\n",
    "    - <font color='#FF7F7F'>Only 3 columns in the dataset, Pokemon, Type1, Type2</font>\n",
    "    - <font color='#FF7F7F'>Type 2 has 50% null values, meaning half the Pokemons only have type1 which makes the identification pointless</font>\n",
    "    - <font color='#FF7F7F'>Data is not uniform, the image resolutions are different which can result in conflicts during data analysis</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f55c6f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Selected Dataset:\n",
    "1. **Pokémon for Data Mining and Machine Learning** - [Kaggle](https://www.kaggle.com/datasets/alopez247/pokemon)\n",
    "    - For nominal analysis\n",
    "2. **Fruits 360** - [Kaggle](https://www.kaggle.com/datasets/moltean/fruits)\n",
    "    - For any CNN related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81862132",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week 2\n",
    "Overview: We visualised and summarised the pokemon data, in order to be aquainted with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199c380",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Imported required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f43c6",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Some required imports\n",
    "import sys\n",
    "assert sys.version_info >= (3,5)    # Python >= 3.5 is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4d7a2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.2\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdcfa9e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. We loaded the dataset, described the attributes, and generated summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532feb7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reads the CSV\n",
    "pokemon = pd.read_csv('pokemon_alopez247.csv')\n",
    "# This displays the top 5 entries, showing its 23 attributes\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c21815",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Attribute Description of the Dataset\n",
    "\n",
    "This database includes 721 Pokémon records from first six generations, with 23 attributes.\n",
    "\n",
    "- **Number**: Unique identifier.\n",
    "- **Name**: Pokémon name.\n",
    "- **Type_1**: Primary type.\n",
    "- **Type_2**: Second type, in case the Pokémon has it.\n",
    "- **Total**: Sum of base stats (health points, attack, defense, special attack, special defense, and speed).\n",
    "- **HP**: Base health points.\n",
    "- **Attack**: Base attack.\n",
    "- **Defense**: Base defense.\n",
    "- **Sp_Atk**: Base special attack.\n",
    "- **Sp_Def**: Base special defense.\n",
    "- **Speed**: Base speed.\n",
    "- **Generation**: Generation when the Pokémon was introduced. Ranges from 1 to 6.\n",
    "- **isLegendary**: Boolean that indicates whether the Pokémon is Legendary or not.\n",
    "- **Color**: Color of the Pokémon.\n",
    "- **hasGender**: Boolean that indicates if the Pokémon can be classified as female or male.\n",
    "- **Pr_male**: If the Pokémon has gender, the probability of being male. The probability of being female is 1 minus this value.\n",
    "- **EggGroup1**: Egg group of the Pokémon.\n",
    "- **EggGroup2**: Second egg group of the Pokémon, if it has two.\n",
    "- **hasMegaEvolution**: If the Pokémon is able to Mega-evolve or not. Boolean value.\n",
    "- **Height_m**: Pokémon height (m)\n",
    "- **Weight_kg**: Pokémon weight (kg)\n",
    "- **Catch_Rate**: Probability of the Pokémon being caught when a Pokéball is thrown at it.\n",
    "- **Body_Style**: Body style of the Pokémon. E.g., Quadruped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226759c6",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Displays the type and number of nulls of each attribute\n",
    "# Note: Almost 0.5 of Type 2 attributes are null, because Type 2 is not a required attribute is an optional add-on. \n",
    "pokemon.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846328e1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generated summary statistics for the numerical attributes of the dataset\n",
    "# It is not a complete dataset becuase there are some null values, which is to be dealt with in the next step.\n",
    "pokemon.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a4660",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Indicates where the null values are, within the dataset.\n",
    "sns.heatmap(pokemon.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d83cff",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Dealt with null values\n",
    "\n",
    "We replaced the null values with another arbitrary value as they are meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe33af2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Attributes will nulls and why they have nulls:\n",
    "\n",
    "1. *Type_2* has around 50% null values as some Pokemons do not have a second type. Removing all the rows with this as null would reduce our dataset to 50% of the size. Removing this column ends the possibility of identifying and analysising the Pokemon's second type. Replacing this as a string called \"None\" solves our problem.\n",
    "\n",
    "2. *Egg_Group_2* has around 75% null value as some Pokemons have only one egg group. Removing all the rows with this as null would reduce our dataset to 25% of the size. Removing this column again ends the possibility of indentifying and analysising the Pokemon's second egg group. Replacing this as a string called \"None\" solves our problem.\n",
    "\n",
    "3. *Pr_Male* has around 11% null values, these Pokemons do not have a gender. Removing these rows or columns will cost us the possibility of identifying and predicting the Pokemon's gender. Replacing this with 999 signifies as the Pokemon as genderless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b04fc7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dealing with null values \n",
    "\n",
    "# changing null values of Type_2 to string \"None\"\n",
    "pokemon['Type_2'].fillna(\"None\", inplace = True)\n",
    "# changing null values of Egg_Group_2 to string \"None\"\n",
    "pokemon['Egg_Group_2'].fillna(\"None\", inplace = True)\n",
    "# changing null values of Pr_Male to 999\n",
    "pokemon['Pr_Male'].fillna(999, inplace = True)\n",
    "\n",
    "# Now there are no more null values.\n",
    "pokemon.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f023a1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Visualising again, now with a complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7293f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generating a box plot to view the numerical data\n",
    "\n",
    "plt.figure(figsize = (30, 10))\n",
    "# Taking all numerical data to plot\n",
    "num_data = pokemon[['Total', 'HP', 'Attack', 'Defense', 'Sp_Atk', 'Sp_Def', 'Speed', 'Generation', 'Height_m', 'Weight_kg', 'Catch_Rate']]\n",
    "# Generating a box plot to visualize the statistical summary \n",
    "sns.boxplot(data = num_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506418f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Dealing with Categorical Data\n",
    "\n",
    "We will convert the categorical data into numerical. Why? (Someone answer this)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e5300",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The data before:\n",
    "categorical_attributes = ['Type_1', 'Type_2', 'Egg_Group_1', 'Egg_Group_2', 'Color', 'Body_Style', 'isLegendary', 'hasMegaEvolution', 'hasGender']\n",
    "pokemon[categorical_attributes].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d633f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Changing the categorical data to numbers.\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "pokemon[categorical_attributes] = enc.fit_transform(pokemon[categorical_attributes]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ad4aa",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now they are all numerical\n",
    "pokemon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d91148",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The data after:\n",
    "pokemon[categorical_attributes].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed7e5d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Dropping Unecessary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ba3a2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number and name are unnecessary because they will not help us classify the target attributes\n",
    "pokemon = pokemon.drop(['Number','Name'], axis=1)\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95844f59",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 7. Plotting the Correlation Matrix\n",
    "We want to see the correlation between each attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bad88",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We want to look at the correlations between each attribute\n",
    "\n",
    "mask = np.array(pokemon.corr())\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "sns.heatmap(pokemon.corr(), mask = mask, annot=True, cmap='viridis', linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbe7a2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7055b264",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Binary Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08309df1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Logistic regression to the training data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Creates the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def binaryClassification(X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "    \n",
    "    ss_train_test = StandardScaler()\n",
    "    logisticRegr = LogisticRegression() \n",
    "    logisticRegr.fit(ss_train_test.fit_transform(X_train), y_train)\n",
    "    \n",
    "    # Predicting based off of the test data\n",
    "    predictions = logisticRegr.predict(ss_train_test.fit_transform(X_test))\n",
    "\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "    print('True Positive(TP)  = ', TP)\n",
    "    print('False Positive(FP) = ', FP)\n",
    "    print('True Negative(TN)  = ', TN)\n",
    "    print('False Negative(FN) = ', FN)\n",
    "\n",
    "    # Accuracy of the classifier\n",
    "    accuracy =  (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "    print('Accuracy of the binary classifier = {:0.3f}'.format(accuracy))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7bb0b",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Tried min max scaler instead of standard Scaler :\n",
    "#Min max scaler got a lower answer, and had more false trues, than the StandardScaler..\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# min_max_scaler = preprocessing .MinMaxScaler()\n",
    "\n",
    "# X_train_Binary = min_max_scaler.fit_transform(X_train)\n",
    "# X_test_Binary = min_max_scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a9002",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Binary Classification on Original Data (Without Feature Extraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78bdc27",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Original data without any feature extraction:\n",
    "y = pokemon['isLegendary']\n",
    "# Has all attributes besides isLegendary,because it is the class attri (shouldn't be normalized)\n",
    "X = pokemon.drop('isLegendary', axis =1 )\n",
    "\n",
    "binaryClassification(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c680e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pearson's R Feature Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966d9c7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = pokemon.corr() # computes the standard correlation coefficient (Pearson’s r) between every pair of attributes\n",
    "top_corr = corr_matrix[\"isLegendary\"].sort_values(ascending=False)\n",
    "top_corr = top_corr.sort_values(ascending=False).drop('isLegendary')\n",
    "top_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511b997",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# getting top 5 correlating attributes and visualising it\n",
    "attributes = top_corr.index[:5].tolist()\n",
    "scatter_matrix(pokemon[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8310896",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the top 9 features and then spliting them up to 3 ....\n",
    " \n",
    "\n",
    "pokemon_pearsons_r = pokemon[top_corr.index[:3].tolist()]\n",
    "pokemon_pearsons_r_2 = pokemon[top_corr.index[3:6].tolist()]\n",
    "pokemon_pearsons_r_3 = pokemon[top_corr.index[-3:].tolist()]\n",
    "\n",
    "print(pokemon_pearsons_r.columns.to_list())\n",
    "print(pokemon_pearsons_r_2.columns.to_list())\n",
    "print(pokemon_pearsons_r_3.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f01b4",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attributes = top_corr.index[:5].tolist()\n",
    "scatter_matrix(pokemon[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea95859",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Binary Classification on Pearsons R data (1st Feature Extraction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c494723",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h5>Binary Classification Using the Top 3 Features</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4abf55",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Features extracted using pearsons r..\n",
    "y = pokemon['isLegendary']\n",
    "# Has only the top 3 features that has been extracted using pearsons r.\n",
    "X = pokemon_pearsons_r\n",
    "print(\"features that are being used: \", X.keys().tolist())\n",
    "print(\"---------\")\n",
    "binaryClassification(X,y)\n",
    "#mutual information\n",
    "#chi square."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09064a55",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h5>Binary Classification Using the Top 7 Features</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db9e4a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Features extracted using pearsons r..\n",
    "y = pokemon['isLegendary']\n",
    "# Has only the top 5 features that has been extracted using pearsons r.\n",
    "X = pokemon_pearsons_r_2\n",
    "print(\"features that are being used: \", X.keys().tolist())\n",
    "print(\"---------\")\n",
    "binaryClassification(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d175f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h5>Binary Classification Using the Top 10 Features</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ced7d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Features extracted using pearsons r..\n",
    "y = pokemon['isLegendary']\n",
    "# Has only the top 7 features that has been extracted using pearsons r.\n",
    "X = pokemon_pearsons_r_3\n",
    "\n",
    "print(\"features that are being used: \", X.keys().tolist())\n",
    "print(\"---------\")\n",
    "binaryClassification(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161587c",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Embedded Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8be5b",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is wrong, this is using the normal data (all attrib in X), instead of actually using the extracted attri in X.\n",
    "\n",
    "y = pokemon['isLegendary']\n",
    "# Has all attributes besides isLegendary,because it is the class attri (shouldn't be normalized)\n",
    "X = pokemon.drop('isLegendary', axis =1 )\n",
    "\n",
    "X_train_embedded, X_test_embedded, y_train_embedded, y_test_embedded = train_test_split(X, y, test_size=0.3, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d3c36",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train model using lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_embedded, y_train_embedded)\n",
    "\n",
    "# perform feature selection\n",
    "pokemon_embedded_methods = [feature for feature, weight in zip(X.columns.values, lasso.coef_) if weight != 0]\n",
    "print(\"Features that have been selected are: \",pokemon_embedded_methods)\n",
    "print(\"---------\")\n",
    "binaryClassification(pokemon[pokemon_embedded_methods],y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04d0f7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Applying PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5ed80",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "y = pokemon['isLegendary']\n",
    "# Has all attributes besides isLegendary,because it is the class attri (shouldn't be normalized)\n",
    "X = pokemon.drop('isLegendary', axis =1 )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "exp_variance = pca.exp_variance_ratio_\n",
    "\n",
    "cm = confusion_matrix(y_test, exp_variance)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, exp_variance).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "# Accuracy of the classifier\n",
    "accuracy =  (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "print('Accuracy of the binary classifier = {:0.3f}'.format(accuracy))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Week 3 Conclusions\n",
    "- What kind of information did you learn, as a result of the above experiments?\n",
    "- What features are more important/reliable for the class? Less reliable?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b53d3ebc9ab588da17f6fff91cb07c6116aee8ae1f5ab3dcaac78344e70010d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
